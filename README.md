# Vibeify - Mood Detection & Music Recommendation
Vibeify is a mood-aware Android application that recommends a single Spotify track tailored to the userâ€™s current emotional state. Using Google ML Kitâ€™s face-detection API, the app classifies the userâ€™s expression into five moods: angry, sad, neutral, happy, or super happy and instantly streams a 15-second preview that matches the detected vibe. A built-in QR code lets onlookers open the same song on their own devices, creating an engaging and shareable music experience.


## Sample UI
![Updated Sample UI](https://github.com/user-attachments/assets/f9cb04b8-4b38-4429-b619-bfb0f83183ae)

## Getting Started
1. **Clone the repository**

   ```bash
   git clone https://github.com/judiemosinabre/vibeify.git
   cd vibeify
   ```

2. **Add your Spotify API keys**
<br>In the project root (same folder as settings.gradle.kts), <br>
create a file named gradle.properties if it isnâ€™t there already.
Paste your credentials:
```bash
  #gradle.properties  (in .gitignore â€“ never pushed)
  SPOTIFY_CLIENT_ID=yourRealClientIdHere
  SPOTIFY_CLIENT_SECRET=yourRealClientSecretHere
```

3. **Sync & build**
<br>In AndroidÂ Studio click "Sync Project"

4. **Configure GoogleÂ MLÂ Kit Face Detection**
<br>Follow the official MLÂ Kit Face Detection setup guide.

5. **Run the app**

## Features and Use Cases

### 1. Face Emotion Detection  
- Uses the deviceâ€™s front camera with Google ML Kit Face Detection API.  
- Real-time classification into angry, sad, neutral, happy, super happy. 
- Tracks facial features such as smiling probability, eye openness, and head tilt in real-time.

### 2. Mood-Mapped Music Recommender  
- Fetches a random track from curated lists per mood.

### 3. Spotify Integration  
- 15-sec previews from Spotify API or Firebase MP3s when previews are missing.

### 4. Interactive Exhibit Mode  
- Displays QR linking directly to the Spotify track.

### 5. Share
- Custom Text along with the track link in spotify for redirection.
```bash
  "Vibeify recommends this song!" + "\n" +
  "\nðŸŽ§ Listen On Spotify: " + trackUrl);
  ```

## Technology Stack
- **Mobile Platform:** Android Studio (Java)
- **AI/ML:** Google ML Kit â€” Face Detection API for emotion recognition  
- **Music API:** Spotify Web API
- **Media:** Android MediaPlayer
- **UI Assets:** Glide (for album images), XML Layout, ZXing for QR generation
- **Backend (optional):** Firebase (Storage)


## Target Users
- Music lovers (ages 13â€“30)  
- Students, social media users, and busy professionals
- Tech fair visitors looking for an interactive and emotional music experience


## How It Works
1. User opens the app and grants camera access.  
2. The front camera captures facial expressions and sends data to ML Kit for emotion analysis.  
3. The app infers the current mood (happy, super happy, sad, neutral, angry).  
4. Based on the mood, a corresponding Spotify track is chosen.  
5. A 15-second song preview matching the mood plays instantly.  
6. A QR code can be scanned to open the song directly on another device.

## Reflection
Creating Vibeify has been an insightful journey that pushed me to combine machine learning, Android development, and user experience design into a single real-time application. One of the most challenging yet rewarding aspects was fine-tuning the mood detection algorithm. I experimented with smile probability, head tilt, and eye openness to classify moods into five categories: Angry, Sad, Neutral, Happy, and Super Happy. Adjusting the thresholds to achieve accurate and consistent detection across different faces and conditions taught me the importance of iterative testing and real-world validation in ML-based applications.
<br><br>
Integrating the Spotify Web API also deepened my understanding of working with external APIs and handling authentication, particularly using the Client Credentials Flow. When Spotify preview URLs were unavailable, I implemented a fallback using Firebase Storage, which introduced me to cloud storage and media handling on Android. Overall, building Vibeify helped me strengthen my technical skills while learning how to deliver a responsive, intuitive, and engaging app that connects emotion with music in real time.


